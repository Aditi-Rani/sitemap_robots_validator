# ğŸ—‚ï¸ Sitemap.xml & Robots.txt Validator

A simple Python CLI tool that checks the availability and validity of `sitemap.xml` and `robots.txt` â€” two crucial files for search engine crawling and indexing.

---

## âœ… Features

- Automatically constructs URLs for:
  - `sitemap.xml`
  - `robots.txt`
- Checks if the files are present and accessible
- Displays:
  - HTTP status codes
  - Content-Type
  - Errors (if any)
- CLI-based: Paste any domain and get results in seconds!

---

## ğŸš€ How to Run

### 1. Clone the repository

```bash
git clone https://github.com/Aditi-Rani/sitemap_robots_validator
```
```bash
cd sitemap-robots-validator
```

### 2. Install dependencies
```bash
pip install -r requirements.txt
```
### 3. Run the script
```bash
python sitemap_robots_validator.py
```
### 4. Enter the URL when prompted
```bash
Enter the website URL (include https://): https://example.com
```